{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/01_Meteorology data_La Molina CIP station 2013-2022.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m longitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m76.95\u001b[39m \u001b[38;5;66;03m#@param {type:\"number\"}\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_to_read \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLa Molina\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m     station_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/01_Meteorology data_La Molina CIP station 2013-2022.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     station_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/01_Meteorology data_San Ramon CIP station 2019-2022.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pieropalacios\\.conda\\envs\\piero\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pieropalacios\\.conda\\envs\\piero\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\pieropalacios\\.conda\\envs\\piero\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pieropalacios\\.conda\\envs\\piero\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/01_Meteorology data_La Molina CIP station 2013-2022.xlsx'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "date_from = '2020-01-01' #@param {type:\"date\"}\n",
    "date_to = \"2021-01-01\" #@param {type:\"date\"}\n",
    "path_to_read = \"La Molina\" #@param [\"La Molina\", \"San Ramon\"]\n",
    "latitude = -12.08 #@param {type:\"number\"}\n",
    "longitude = -76.95 #@param {type:\"number\"}\n",
    "\n",
    "\n",
    "if path_to_read == \"La Molina\":\n",
    "    station_df = pd.read_excel(\"/content/01_Meteorology data_La Molina CIP station 2013-2022.xlsx\")\n",
    "else:\n",
    "    station_df = pd.read_excel(\"/content/01_Meteorology data_San Ramon CIP station 2019-2022.xlsx\")\n",
    "\n",
    "api_key = \"28884cc8d61e46cbb3793258221912\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data from Open-Meteo\n",
    "def fetch_weather_data_open_meteo(latitude, longitude, date_from,date_to):\n",
    "    base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": date_from,\n",
    "        \"end_date\": date_to,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m,rain\",\n",
    "        \"timezone\": \"UTC\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data from Open-Meteo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch data from WeatherAPI\n",
    "def fetch_weather_data_weatherapi(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch weather data from WeatherAPI for a given latitude, longitude, and date range.\n",
    "    \n",
    "    Parameters:\n",
    "        latitude (float): Latitude of the location.\n",
    "        longitude (float): Longitude of the location.\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of JSON responses for each date in the range.\n",
    "    \"\"\"\n",
    "    # api_key = os.getenv('WEATHER_API_KEY')\n",
    "    if not api_key:\n",
    "        print(\"API key for WeatherAPI is not set.\")\n",
    "        return None\n",
    "\n",
    "    base_url = \"http://api.weatherapi.com/v1/history.json\"\n",
    "    current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    all_data = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        params = {\n",
    "            \"key\": api_key,\n",
    "            \"q\": f\"{latitude},{longitude}\",\n",
    "            \"dt\": date_str\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            all_data.append(response.json())\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from WeatherAPI for {date_str}: {e}\")\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def process_open_meteo_data(data):\n",
    "    if not data or 'hourly' not in data:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data['hourly'])\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df.set_index('time', inplace=True)\n",
    "    df.rename(columns={\n",
    "        'temperature_2m': 'Temperature_OpenMeteo',\n",
    "        'relative_humidity_2m': 'Humidity_OpenMeteo',\n",
    "        'rain': 'Rain_OpenMeteo'\n",
    "    }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_weatherapi_data(data_list):\n",
    "    \"\"\"\n",
    "    Process a list of weather data JSON responses into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        data_list (list): List of JSON responses from WeatherAPI.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing processed weather data.\n",
    "    \"\"\"\n",
    "    if not data_list:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for data in data_list:\n",
    "        if 'forecast' in data and data['forecast']['forecastday']:\n",
    "            hourly_data = data['forecast']['forecastday'][0]['hour']\n",
    "            df = pd.DataFrame(hourly_data)\n",
    "            df['time'] = pd.to_datetime(df['time'])\n",
    "            df.set_index('time', inplace=True)\n",
    "            df.rename(columns={\n",
    "                'temp_c': 'Temperature_WeatherAPI',\n",
    "                'humidity': 'Humidity_WeatherAPI',\n",
    "                'precip_mm': 'Rain_WeatherAPI'\n",
    "            }, inplace=True)\n",
    "            all_dfs.append(df)\n",
    "        else:\n",
    "            print(\"Warning: 'forecast' data missing in response.\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all daily DataFrames\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "\n",
    "    # Handle overlapping date ranges by removing duplicate indices, keeping the first occurrence\n",
    "    combined_df = combined_df[~combined_df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Ensure consistent hourly data by reindexing\n",
    "    full_time_range = pd.date_range(start=combined_df.index.min(), end=combined_df.index.max(), freq='H')\n",
    "    combined_df = combined_df.reindex(full_time_range)\n",
    "\n",
    "    # Handle missing data (e.g., due to inconsistent hourly data)\n",
    "    combined_df['Temperature_WeatherAPI'].interpolate(method='time', inplace=True)\n",
    "    combined_df['Humidity_WeatherAPI'].interpolate(method='time', inplace=True)\n",
    "    combined_df['Rain_WeatherAPI'].fillna(0, inplace=True)  # Assuming missing rain data means no rain\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def plot_comparison(df_combined, variable, ylabel, df_station, variable_station):\n",
    "    \"\"\"\n",
    "    Plots monthly trends with hourly averages and standard deviations for two data sources and a station.\n",
    "    Each month is displayed in a separate subplot (arranged from January to December).\n",
    "\n",
    "    Parameters:\n",
    "    - df_combined: DataFrame containing combined data from Open-Meteo and WeatherAPI.\n",
    "    - variable: String representing the variable name to compare (e.g., 'Temperature').\n",
    "    - ylabel: Label for the Y-axis (e.g., 'Temperature (°C)').\n",
    "    - df_station: DataFrame containing station data for comparison.\n",
    "    - variable_station: String representing the column name for the station variable.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure relevant columns are numeric\n",
    "    df_combined[f'{variable}_OpenMeteo'] = pd.to_numeric(df_combined[f'{variable}_OpenMeteo'], errors='coerce')\n",
    "    df_combined[f'{variable}_WeatherAPI'] = pd.to_numeric(df_combined[f'{variable}_WeatherAPI'], errors='coerce')\n",
    "    df_station[variable_station] = pd.to_numeric(df_station[variable_station], errors='coerce')\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df_combined = df_combined.dropna(subset=[f'{variable}_OpenMeteo', f'{variable}_WeatherAPI'])\n",
    "    df_station = df_station.dropna(subset=[variable_station])\n",
    "\n",
    "    # Add Hour and Month columns\n",
    "    df_combined['Hour'] = df_combined.index.hour\n",
    "    df_combined['Month'] = df_combined.index.month\n",
    "    df_station['Hour'] = df_station.index.hour\n",
    "    df_station['Month'] = df_station.index.month\n",
    "\n",
    "    # Group by Month and Hour\n",
    "    grouped_open_meteo = df_combined.groupby(['Month', 'Hour'])[f'{variable}_OpenMeteo']\n",
    "    grouped_weatherapi = df_combined.groupby(['Month', 'Hour'])[f'{variable}_WeatherAPI']\n",
    "    grouped_station = df_station.groupby(['Month', 'Hour'])[variable_station]\n",
    "\n",
    "    mean_open_meteo = grouped_open_meteo.mean().unstack(level=0)\n",
    "    std_open_meteo = grouped_open_meteo.std().unstack(level=0)\n",
    "\n",
    "    mean_weatherapi = grouped_weatherapi.mean().unstack(level=0)\n",
    "    std_weatherapi = grouped_weatherapi.std().unstack(level=0)\n",
    "\n",
    "    mean_station = grouped_station.mean().unstack(level=0)\n",
    "    std_station = grouped_station.std().unstack(level=0)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 12), sharex=True, sharey=True)\n",
    "    fig.suptitle(f'Monthly {ylabel} Trends by Hour (with Standard Deviation)', fontsize=16)\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        ax = axes[(month - 1) // 3, (month - 1) % 3]  # Calculate subplot position\n",
    "\n",
    "        if month in mean_open_meteo.columns:\n",
    "            ax.errorbar(mean_open_meteo.index, mean_open_meteo[month], yerr=std_open_meteo[month],\n",
    "                        fmt='-o', label='Open-Meteo', capsize=3)\n",
    "        if month in mean_weatherapi.columns:\n",
    "            ax.errorbar(mean_weatherapi.index, mean_weatherapi[month], yerr=std_weatherapi[month],\n",
    "                        fmt='-x', label='WeatherAPI', capsize=3)\n",
    "        if month in mean_station.columns:\n",
    "            ax.errorbar(mean_station.index, mean_station[month], yerr=std_station[month],\n",
    "                        fmt='-*', label='Station', capsize=3)\n",
    "\n",
    "        ax.set_title(f'Month {month}')\n",
    "        ax.grid(True)\n",
    "        ax.set_xticks(range(0, 24, 3))  # Show every 3rd hour for clarity\n",
    "        ax.set_xlabel('Hour of the Day')\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    # Add a single legend for all plots\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=3)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title and legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['Time'] = station_df['Time'].astype(str)\n",
    "station_df['Time'] = station_df['Time'].apply(\n",
    "    lambda x: x.zfill(2) + \":00:00\" if x.isdigit() and len(x) <= 2 else x\n",
    ")\n",
    "\n",
    "station_df['DateTime'] = pd.to_datetime(\n",
    "    station_df[\"Year\"].astype(str) + \"-\" +\n",
    "    station_df['Month'].astype(str).str.zfill(2) + \"-\" +\n",
    "    station_df['Day'].astype(str).str.zfill(2) + \" \" +\n",
    "    station_df['Time'].astype(str), # Remove .str to access the string values directly\n",
    "    errors='coerce'  # Handle errors by setting invalid values to NaT\n",
    ")\n",
    "\n",
    "station_df.set_index('DateTime', inplace=True)\n",
    "station_df['DateTime'] = station_df.index\n",
    "\n",
    "date_from_dt = pd.to_datetime(date_from)\n",
    "date_to_dt = pd.to_datetime(date_to)\n",
    "station_df_subset = station_df[(station_df['DateTime'] >= date_from_dt) & (station_df['DateTime'] <= date_to_dt)]\n",
    "station_df_subset\n",
    "\n",
    "# Fetch data from both APIs\n",
    "data_open_meteo = fetch_weather_data_open_meteo(latitude, longitude, date_from, date_to)\n",
    "data_weatherapi = fetch_weather_data_weatherapi(latitude, longitude, date_from, date_to)\n",
    "\n",
    "# Process the data\n",
    "df_open_meteo = process_open_meteo_data(data_open_meteo)\n",
    "df_weatherapi = process_weatherapi_data(data_weatherapi)\n",
    "\n",
    "# Merge the dataframes on time index\n",
    "df_combined = pd.merge(df_open_meteo, df_weatherapi, left_index=True, right_index=True, how='outer')\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(df_combined, 'Temperature', 'Temperature (°C)',station_df,\"Ta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
